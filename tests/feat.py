import pandas as pd
import numpy as np
import featuretools as ft
import os
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from sklearn.linear_model import LinearRegression

# Read data from CSV file
csv_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'synz.csv')
df = pd.read_csv(csv_path)
# Clean data: drop rows with missing essential stats
df = df.dropna(subset=['Member', 'Power', 'Kills', 'Level', 'Prof Lvl', 'Gift Lvl'])

# 1. Setup Featuretools EntitySet
es = ft.EntitySet(id="guild_data")

# Create an entity from the dataframe
# Need to set a unique index for featuretools
df['player_id'] = df['Member'] # Use member name as a unique ID for this example
es.add_dataframe(dataframe_name="players",
                 dataframe=df,
                 index="player_id")

# 2. Run Automated Feature Engineering (AFE)
# This generates many potential features like "SUM(Alliance.Kills)" or "MEAN(Alliance.Power)"
feature_matrix, feature_defs = ft.dfs(entityset=es,
                                      target_dataframe_name="players",
                                      agg_primitives=["sum", "mean", "min", "max", "std"],
                                      verbose=True)

# Add Member and Alliance columns back to feature_matrix for display
feature_matrix['Member'] = df.set_index('player_id')['Member']
feature_matrix['Alliance'] = df.set_index('player_id')['Alliance']

print("\n--- Generated Feature Matrix (Sample of New Composite Scores) ---")
# Display newly generated features alongside original stats
available_cols = [col for col in ['Power', 'Kills', 'Level'] if col in feature_matrix.columns]
print(feature_matrix[available_cols].to_markdown())


# 3. Use an ML model to interpret which generated feature is strongest
# We can define a simple "Target Score" (e.g., a combination of stats)
feature_matrix['target_strength'] = (feature_matrix['Power'] * 0.1) + \
                                    (feature_matrix['Kills'] * 2) + \
                                    (feature_matrix['Level'] * 10)

# 4. Train a simple Linear Regression model to find a single composite score/coefficient
# This model will try to predict our 'target_strength' using the generated features
features_for_model = feature_matrix.drop(['target_strength'], axis=1).select_dtypes(include=[np.number])
# Clean any NaNs generated by Featuretools for the model
features_for_model = features_for_model.dropna()
target = feature_matrix.loc[features_for_model.index, 'target_strength']

model = LinearRegression()
model.fit(features_for_model, target)

# 5. The resulting 'composite score' is what the linear model predicts
composite_scores = model.predict(features_for_model)
# Normalize to 0-100 scale
min_score = composite_scores.min()
max_score = composite_scores.max()
normalized_scores = ((composite_scores - min_score) / (max_score - min_score)) * 100
feature_matrix.loc[features_for_model.index, 'Composite_Recruit_Score'] = normalized_scores

print("\n--- Players Ranked by Composite Recruit Score (Higher is better) ---")
ranked_players = feature_matrix.sort_values(by='Composite_Recruit_Score', ascending=False)
display_cols = [col for col in ['Alliance', 'Member', 'Composite_Recruit_Score', 'Power', 'Kills', 'Level'] 
                if col in ranked_players.columns]
# Format Composite_Recruit_Score to 1 decimal place
display_df = ranked_players[display_cols].copy()
if 'Composite_Recruit_Score' in display_df.columns:
    display_df['Composite_Recruit_Score'] = display_df['Composite_Recruit_Score'].round(1)
# Add rank as the first column
display_df.insert(0, 'Rank', range(1, len(display_df) + 1))
print(display_df.to_markdown(index=False))

# Count players by alliance
print("\n--- Player Count by Alliance ---")
alliance_counts = feature_matrix['Alliance'].value_counts().sort_values(ascending=False)
for alliance, count in alliance_counts.items():
    print(f"{alliance}: {count} players")
